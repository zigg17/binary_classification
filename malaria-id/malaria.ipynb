{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg0W4k9bRx2O"
      },
      "source": [
        "# **Imports:**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path in Google Drive\n",
        "model_iter = input('Enter model iteration: ')"
      ],
      "metadata": {
        "id": "pFTtfrLDb54e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pALvtROrRR3R"
      },
      "outputs": [],
      "source": [
        "# basic imports\n",
        "import sys\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "\n",
        "# Pytorch libaries\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader, random_split, ConcatDataset, Subset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# For loop\n",
        "from timeit import default_timer as timer\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# For visualizing and troubleshooting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# For saving a path and loading\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import zipfile\n",
        "\n",
        "print(\"Imported successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hzznk7AW5Gy"
      },
      "outputs": [],
      "source": [
        "print(f\"Torch version: {torch.__version__}\\n\")\n",
        "print(f\"Torchvision version: {torchvision.__version__}\\n\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\\n\")\n",
        "print(f\"cuDNN version: {torch.backends.cudnn.version()}\\n\")\n",
        "print(f\"Python version: {sys.version}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krWRA_yaSkgK"
      },
      "source": [
        "# **Training loop setup:**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWypUfYtTESx"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvjKeezihlGN"
      },
      "outputs": [],
      "source": [
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, download skipped\")\n",
        "else:\n",
        "  print(\"helper_functions.py DNE, download initiated\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)\n",
        "\n",
        "from helper_functions import accuracy_fn, print_train_time\n",
        "\n",
        "if 'accuracy_fn' and 'print_train_time' in dir():\n",
        "    print(\"Both functions are imported.\")\n",
        "else:\n",
        "    print(\"Accuracy function is not imported.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bwJnoV81SqLz"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "              data_loader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              optimizer: torch.optim.Optimizer,\n",
        "              accuracy_fn,\n",
        "              device: torch.device = device,\n",
        "               ):\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # For training\n",
        "  model.train()\n",
        "  for batch, (image, label) in enumerate(data_loader):\n",
        "\n",
        "    # Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass\n",
        "    image = image.to(device)\n",
        "    label = label.to(device, dtype=torch.float)\n",
        "    pred = model(image).squeeze()\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = loss_fn(pred, label)\n",
        "    train_loss += loss\n",
        "    train_acc += accuracy_fn(y_true = label,\n",
        "                             y_pred = torch.round(torch.sigmoid(pred)))\n",
        "\n",
        "    # Backprop\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "  # For calculating average trainloss over every batch in each epoch\n",
        "  scheduler.step()\n",
        "  train_loss /= len(data_loader)\n",
        "  train_acc /= len(data_loader)\n",
        "  return train_loss, train_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vnD_z6N3Sslp"
      },
      "outputs": [],
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "                  data_loader: torch.utils.data.DataLoader,\n",
        "                  loss_fn: torch.nn.Module,\n",
        "                  optimizer: torch.optim.Optimizer,\n",
        "                  accuracy_fn,\n",
        "                  device: torch.device = device):\n",
        "\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    for batch, (image, label) in enumerate(data_loader):\n",
        "      # Forward pass\n",
        "      image = image.to(device)\n",
        "      label = label.to(device, dtype=torch.float)\n",
        "      pred = model(image).squeeze()\n",
        "\n",
        "      # Loss calculation\n",
        "      loss = loss_fn(pred, label)\n",
        "      test_loss += loss\n",
        "\n",
        "      # Accuracy calculation\n",
        "      test_acc += accuracy_fn(y_true = label,\n",
        "                              y_pred = torch.round(torch.sigmoid(pred)))\n",
        "\n",
        "    test_loss /= len(data_loader)\n",
        "    test_acc /= len(data_loader)\n",
        "  return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resnet34**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "fWOWKccQuH6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet34(weights='IMAGENET1K_V1')\n",
        "num_ftrs = model.fc.in_features\n",
        "num_classes = 1\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "5sdhQoE6E0cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_CLUM0dcKe2"
      },
      "source": [
        "# **Data Loading:**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/malarianomalaria/cell_images.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "6gApxo6iUgTD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGQHeA5Mi9_p"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_path, transform=None):\n",
        "    return ImageFolder(dataset_path, transform=transform)\n",
        "\n",
        "# Define your transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "combined_dataset = load_dataset('/tmp/cell_images/cell_images', transform=transform)\n",
        "\n",
        "print(f\"Class types: {combined_dataset.classes}\")\n",
        "\n",
        "\n",
        "# Split the subset into train and test sets\n",
        "train_size = int(0.8 * len(combined_dataset))  # 80% for training\n",
        "test_size = len(combined_dataset) - train_size  # 20% for testing\n",
        "train_dataset, test_dataset = random_split(combined_dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders for train and test sets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Checks:**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "n96jUhcAa_Sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_random_images(data_loader, num_images=9):\n",
        "    images = []\n",
        "    labels = []  # Optional: Collect labels if you need them\n",
        "\n",
        "    for image_batch, label_batch in data_loader:\n",
        "        # Convert batch size to a list of indices, shuffle them\n",
        "        indices = torch.randperm(len(image_batch))\n",
        "\n",
        "        # Iterate over shuffled indices to select images randomly\n",
        "        for idx in indices:\n",
        "            images.append(image_batch[idx])\n",
        "            labels.append(label_batch[idx])\n",
        "            if len(images) == num_images:\n",
        "                return images, labels  # Stop when you have enough images\n",
        "\n",
        "    return images, labels  # In case less than num_images are collected\n",
        "\n",
        "# Function to display images\n",
        "def show_images(images, cols=3):\n",
        "    rows = (len(images) + cols - 1) // cols\n",
        "    plt.figure(figsize=(cols * 3, rows * 3))\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(rows, cols, i + 1)\n",
        "        # Assuming images are in tensor format and need to be converted for display\n",
        "        plt.imshow(image.numpy().transpose(1, 2, 0))\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get and display the images\n",
        "random_images, random_labels = get_random_images(train_dataloader, 9)\n",
        "show_images(random_images)"
      ],
      "metadata": {
        "id": "rOqUz9g2Xsku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_labels(data_loader):\n",
        "    label_count = Counter()\n",
        "\n",
        "    for _, labels in data_loader:\n",
        "        label_count.update(labels.tolist())\n",
        "\n",
        "    return label_count\n",
        "\n",
        "def calculate_proportions(label_count):\n",
        "    total_samples = sum(label_count.values())\n",
        "    proportions = {label: round(count / total_samples, 3) for label, count in label_count.items()}\n",
        "    return proportions\n",
        "\n",
        "train_label_count = count_labels(train_dataloader)\n",
        "test_label_count = count_labels(test_dataloader)\n",
        "\n",
        "train_proportions = calculate_proportions(train_label_count)\n",
        "test_proportions = calculate_proportions(test_label_count)\n",
        "\n",
        "print(\"Training set label counts:\", train_label_count)\n",
        "print(\"\")\n",
        "print(\"Training set label proportions:\")\n",
        "for label, prop in train_proportions.items():\n",
        "    print(f\"Label {label}: {prop}\")\n",
        "\n",
        "print(\"Testing set label counts:\", test_label_count)\n",
        "print(\"\")\n",
        "print(\"Testing set label proportions:\")\n",
        "for label, prop in test_proportions.items():\n",
        "    print(f\"Label {label}: {prop}\")\n"
      ],
      "metadata": {
        "id": "YFXmP-NUZ5Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training:**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cwdzYpklbWQO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mD254E5xcPmt"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=18, gamma=0.1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fudgfGphX0w"
      },
      "outputs": [],
      "source": [
        "epochCount = []\n",
        "trainLosses = []\n",
        "testLosses = []\n",
        "trainAccuracies = []\n",
        "testAccuracies = []\n",
        "\n",
        "epochs = 2\n",
        "timeStart = timer()\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\")\n",
        "  print(\"----------------------------------\")\n",
        "  train_loss, train_acc = train_step(model = model,\n",
        "                                      data_loader = train_dataloader,\n",
        "                                      loss_fn = loss_fn,\n",
        "                                      optimizer = optimizer,\n",
        "                                      accuracy_fn = accuracy_fn,\n",
        "                                      device = device)\n",
        "  print(f\"Train loss: {train_loss: 5f} | Train acc: {train_acc:.2f}\")\n",
        "\n",
        "  test_loss, test_acc = test_step(model = model,\n",
        "                                      data_loader = test_dataloader,\n",
        "                                      loss_fn = loss_fn,\n",
        "                                      optimizer = optimizer,\n",
        "                                      accuracy_fn = accuracy_fn,\n",
        "                                      device = device)\n",
        "  print(f\"Test loss: {test_loss: 5f} | Test acc: {test_acc:.2f}\\n\")\n",
        "\n",
        "  epochCount.append(epoch)\n",
        "  trainLosses.append(train_loss)\n",
        "  testLosses.append(test_loss)\n",
        "  trainAccuracies.append(train_acc)\n",
        "  testAccuracies.append(test_acc)\n",
        "\n",
        "timeEnd = timer()\n",
        "totalTrainTime = print_train_time(start = timeStart,\n",
        "                                  end = timeEnd,\n",
        "                                  device = str(next(model.parameters()).device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochCount1 = np.array(epochCount)\n",
        "trainLosses1 = np.array([tensor.detach().cpu() for tensor in trainLosses])\n",
        "testLosses1 = np.array([tensor.detach().cpu() for tensor in testLosses])\n",
        "trainAccuracies1 = np.array(trainAccuracies)\n",
        "testAccuracies1 = np.array(testAccuracies)\n",
        "\n",
        "df = pd.DataFrame({\"Epoch\": epochCount1,\n",
        "                   \"Train Loss\": trainLosses1,\n",
        "                   \"Test Loss\": testLosses1,\n",
        "                   \"Train Accuracy\": trainAccuracies1,\n",
        "                   \"Test Accuracy\": testAccuracies1})"
      ],
      "metadata": {
        "id": "vxrWId4RJTLN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDVQtIAMRxQs"
      },
      "source": [
        "# **Model saving:**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive_path = Path('/content/drive/My Drive/models' + '/' + model_iter)\n",
        "drive_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Create a model save path\n",
        "modelName = model_iter + '.pth'\n",
        "modelSavePath = drive_path / modelName\n",
        "\n",
        "print(f\"SAVING MODEL TO: {modelSavePath}\")\n",
        "\n",
        "# Saving model info to text file\n",
        "def save_model_info(model, epochs, total_train_time, optimizer, loss_fn, file_path, transform):\n",
        "    with open(file_path, 'w') as file:\n",
        "        # Model architecture\n",
        "        file.write('**Model Architecture:**\\n\\n')\n",
        "        file.write(str(model))\n",
        "        file.write('\\n\\n')\n",
        "\n",
        "        # Transformations\n",
        "        file.write('**Transformations:**\\n\\n')\n",
        "        file.write(str(transforms))\n",
        "        file.write('\\n\\n')\n",
        "\n",
        "        # Optimizer details\n",
        "        file.write('**Optimizer Details:**\\n\\n')\n",
        "        file.write(str(optimizer))\n",
        "        file.write('\\n\\n')\n",
        "\n",
        "        # Loss function details\n",
        "        file.write('**Loss Function:**\\n\\n')\n",
        "        file.write(str(loss_fn))\n",
        "        file.write('\\n\\n')\n",
        "\n",
        "        # Number of epochs\n",
        "        file.write('**Number of Epochs:**\\n\\n')\n",
        "        file.write(f'{epochs}\\n\\n')\n",
        "\n",
        "        # Total training time\n",
        "        file.write('**Total Training Time:**\\n\\n')\n",
        "        file.write(f'{total_train_time:.2f} seconds\\n')\n",
        "\n",
        "textName = model_iter + '.txt'\n",
        "modelInfoSavePath = drive_path / textName\n",
        "save_model_info(model, epochs, totalTrainTime, optimizer, loss_fn, modelInfoSavePath, transform)\n",
        "print(f\"Model information saved to {modelInfoSavePath}\")\n",
        "\n",
        "# Example model save (replace `model.state_dict()` with your actual model's state dict)\n",
        "torch.save(obj=model.state_dict(), f=modelSavePath)"
      ],
      "metadata": {
        "id": "5Bp_yIrUqTZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Plotting:**"
      ],
      "metadata": {
        "id": "lZunYxu3Vj9x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame containing the epoch, training loss, and test loss data\n",
        "sns.set()  # Sets the default seaborn style\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='Epoch', y='Train Loss', data=df, label='Train Loss', color = 'red')\n",
        "sns.lineplot(x='Epoch', y='Test Loss', data=df, label='Test Loss', color = 'darkred')\n",
        "\n",
        "plt.title('Training vs Test Losses Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.xticks(ticks=range(0, epochs, 1))\n",
        "\n",
        "# Saving the second graph\n",
        "graph_save_path_2 = drive_path / 'loss_plot.png'\n",
        "plt.savefig(graph_save_path_2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ggwG8biiJncw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accuracy Plotting:**"
      ],
      "metadata": {
        "id": "_RkBw9F-Vcsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame containing the epoch, training loss, and test loss data\n",
        "sns.set()  # Sets the default seaborn style\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.lineplot(x='Epoch', y='Train Accuracy', data=df, label='Train Loss', color = 'red')\n",
        "sns.lineplot(x='Epoch', y='Test Accuracy', data=df, label='Test Loss', color = 'darkred')\n",
        "\n",
        "plt.title('Training vs Test Accuracies Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.xticks(ticks=range(0, epochs, 1))\n",
        "\n",
        "# Saving the second graph\n",
        "graph_save_path_2 = drive_path / 'accuracy_plot.png'\n",
        "plt.savefig(graph_save_path_2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B1csigcVPaTG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}